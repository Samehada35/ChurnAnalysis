# Load the mlbench library
library(mlbench)
# If not available, install the package
#install.packages("mlbench")
# Load the Ionosphere data in the R environment
data("Ionosphere")
# View the data
View(Ionosphere)

# Load the rpart library
library(rpart)
# If not available, install the package
#install.packages("rpart")

# Set a seed
set.seed(42)
# Add a column to the dataset and insert 1 foo training, else 0
Ionosphere[, "train"] <- ifelse(runif(nrow(Ionosphere))<0.8,1,0)
# Split the Ionosphere data
trainset <- Ionosphere[Ionosphere$train == 1,]
testset <- Ionosphere[Ionosphere$train == 0,]
# The column ’train’ is now useless ; we remove it
trainColNum <- grep("train", names(trainset))
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]

# Build the model
rpart_model <- rpart(Class~., data = trainset, method = "class")
# Plot the tree
plot(rpart_model)
text(rpart_model)

typeColNum <- grep("Class", names(Ionosphere))
# Make predictions with built model on the test set
rpart_predict <- predict(rpart_model, testset[,-typeColNum], type = "class")
# Compute the proportion of correct prediction
mean(rpart_predict == testset$Class)
# Produce a confusion matrix from the results
table(pred = rpart_predict, true = testset$Class)

# Cost-complexity pruning
printcp(rpart_model)
# Get the index of this lowest xerror
opt <- which.min(rpart_model$cptable[,"xerror"])
cp <- rpart_model$cptable[opt, "CP"]
cp
# Finally, we prune the tree
pruned_model <- prune(rpart_model, cp)
plot(pruned_model) 
text(pruned_model)

# Compute the proportion of correct prediction with the pruned_model
rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
mean(rpart_pruned_predict == testset$Class)


multiple_runs_classification <- function(train_fraction, n, dataset, prune_tree = FALSE){
  fraction_correct <- rep(NA, n)
  
  set.seed(42)
  
  for(i in 1:n){
    dataset <- dataset[sample(nrow(dataset)),]
    dataset[, "train"] <- ifelse(runif(nrow(dataset))<train_fraction,1,0)
    trainset <- dataset[dataset$train == 1,]
    testset <- dataset[dataset$train == 0,]
    trainColNum <- grep("train", names(trainset))
    trainset <- trainset[,-trainColNum]
    testset <- testset[,-trainColNum]
    
    rpart_model <- rpart(Class~., data = trainset, method = "class")
    
    if(prune_tree){
      pruned_model <- prune(rpart_model, cp)
      rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
      fraction_correct[i] <- mean(rpart_pruned_predict == testset$Class);
    }else{
      rpart_predict <- predict(rpart_model, testset[,-typeColNum], type = "class")
      fraction_correct[i] <- mean(rpart_predict == testset$Class);
    }
  }
  
  return(fraction_correct)
  
}


# Make 50 runs, without pruning
unpruned_set <- multiple_runs_classification(0.8, 50, Ionosphere)
mean(unpruned_set)
sd(unpruned_set)
# Make 50 runs, with pruning
pruned_set <- multiple_runs_classification(0.8, 50, Ionosphere, prune_tree = TRUE)
mean(pruned_set)
sd(pruned_set)

